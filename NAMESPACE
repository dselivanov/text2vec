# Generated by roxygen2: do not edit by hand

S3method(create_dtm,itoken)
S3method(create_dtm,itoken_parallel)
S3method(create_dtm,list)
S3method(create_tcm,itoken)
S3method(create_tcm,itoken_parallel)
S3method(create_vocabulary,character)
S3method(create_vocabulary,itoken)
S3method(create_vocabulary,itoken_parallel)
S3method(create_vocabulary,list)
S3method(itoken,character)
S3method(itoken,iterator)
S3method(itoken,list)
S3method(itoken_parallel,character)
S3method(itoken_parallel,ifiles_parallel)
S3method(itoken_parallel,list)
S3method(print,text2vec_vocabulary)
export(BNS)
export(Collocations)
export(GloVe)
export(GlobalVectors)
export(LDA)
export(LSA)
export(LatentDirichletAllocation)
export(LatentDirichletAllocationDistributed)
export(LatentSemanticAnalysis)
export(RWMD)
export(RelaxedWordMoversDistance)
export(TfIdf)
export(as.lda_c)
export(char_tokenizer)
export(check_analogy_accuracy)
export(create_dtm)
export(create_tcm)
export(create_vocabulary)
export(dist2)
export(fit)
export(fit_transform)
export(glove)
export(hash_vectorizer)
export(idir)
export(ifiles)
export(ifiles_parallel)
export(itoken)
export(itoken_parallel)
export(normalize)
export(pdist2)
export(perplexity)
export(prepare_analogy_questions)
export(prune_vocabulary)
export(psim2)
export(sim2)
export(space_tokenizer)
export(split_into)
export(vocab_vectorizer)
export(vocabulary)
export(word_tokenizer)
import(Matrix)
import(Rcpp)
import(data.table)
import(digest)
import(methods)
import(mlapi)
importFrom(R6,R6Class)
importFrom(RcppParallel,RcppParallelLibs)
importFrom(foreach,"%do%")
importFrom(foreach,"%dopar%")
importFrom(foreach,foreach)
importFrom(futile.logger,flog.debug)
importFrom(futile.logger,flog.error)
importFrom(futile.logger,flog.info)
importFrom(futile.logger,flog.warn)
importFrom(methods,as)
importFrom(utils,setTxtProgressBar)
importFrom(utils,txtProgressBar)
useDynLib("text2vec", .registration=TRUE)
