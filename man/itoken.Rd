% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/iterators.R
\name{itoken}
\alias{itoken}
\alias{itoken.character}
\alias{itoken.ifiles}
\alias{itoken.ilines}
\alias{itoken.list}
\title{Creates iterator over input object.}
\usage{
itoken(iterable, ...)

\method{itoken}{list}(iterable, chunks_number = 10,
  progessbar = interactive(), ...)

\method{itoken}{character}(iterable, preprocess_function = identity,
  tokenizer = function(x) strsplit(x, " ", TRUE), chunks_number = 10,
  progessbar = interactive(), ...)

\method{itoken}{ifiles}(iterable, preprocess_function = identity,
  tokenizer = function(x) strsplit(x, " ", TRUE),
  progessbar = interactive(), ...)

\method{itoken}{ilines}(iterable, preprocess_function = identity,
  tokenizer = function(x) strsplit(x, " ", TRUE), ...)
}
\arguments{
\item{iterable}{an object from which to generate an iterator.}

\item{...}{arguments passed to other methods (not used at the moment).}

\item{chunks_number}{\code{integer}, the number of pieces that object should be divided into.}

\item{progessbar}{\code{logical} indicates whether to show progress bar.}

\item{preprocess_function}{\code{function} which takes chunk of objects -
\code{character vector} and \bold{do all preprocessing} (including stemming if needed).
Usually \code{preprocess_function} should return \code{character vector} - vector of
preprocessed/cleaned documents. See "Details" section.}

\item{tokenizer}{\code{function} which takes \code{character vector}
from preprocess_function, split it into tokens and returns
\code{list} of \code{character vector}s.
Also you can perform tokenization in \code{preprocess_function}
(actually you should do it when apply any stemming) and then set
\code{tokenizer} = \code{\link{identity}}.}
}
\description{
Creates iterator over input object. This iterator usually used in
following functions : \link{create_vocabulary}, \link{create_corpus}, \link{create_dtm},
\link{vectorizers}, \link{create_tcm}. See them for details.
}
\details{
S3 methods for creating itoken iterator from list of tokens
\itemize{
 \item{\code{list}}{ - all elemets of input list shouild be character tokens}
 \item{\code{character}}{ - raw text source,
 user have to provide tokenizer function}
 \item{\code{ifiles}}{ - from files,
 user have to provide reader function, tokenizer}
 \item{\code{idir}}{ - from dir, same as ifiles}
}
}
\examples{
data("movie_review")
txt <- movie_review[['review']][1:100]
it <- itoken(txt, tolower, word_tokenizer, chunks_number = 10)
}
\seealso{
\link{create_vocabulary}, \link{create_corpus}, \link{create_dtm},
\link{vectorizers}, \link{create_tcm}
}

