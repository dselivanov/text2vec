% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vectorizers.R
\name{vectorizers}
\alias{hash_vectorizer}
\alias{vectorizers}
\alias{vocab_vectorizer}
\title{creates vocabulary or hash based vectorizer.}
\usage{
vocab_vectorizer(vocabulary, grow_dtm = TRUE, skip_grams_window = 0L)

hash_vectorizer(hash_size = 2^18, ngram = c(1L, 1L), signed_hash = FALSE,
  grow_dtm = TRUE, skip_grams_window = 0L)
}
\arguments{
\item{vocabulary}{\code{text2vec_vocabulary} object, see \link{vocabulary}.}

\item{grow_dtm}{\code{logical} should we grow Document-Term matrix
during corpus construction or not.}

\item{skip_grams_window}{\code{integer} window for Term-Cooccurence matrix
construction. 0L points to do not construct such matrix.}

\item{hash_size}{\code{integer} > 0 - number of hash-buckets
for hashing trick (feature hashing). Preferably power of 2 number.}

\item{ngram}{\code{integer} vector. The lower and upper boundary of the range of
n-values for different n-grams to be extracted. All values of n such that}

\item{signed_hash}{\code{logical},  indicating whether to use second hash-function
to reduce impact of collisions.}
}
\value{
vectorizer \code{function}
}
\description{
This function creates text vectorizer function
which used in corpus construction.
}
\examples{
data("movie_review")
N <- 100
vectorizer <- hash_vectorizer(2 ^ 18, c(1L, 2L))
it <- itoken(movie_review$review[1:N], preprocess_function = tolower,
             tokenizer = word_tokenizer, chunks_number = 10)
corpus <- create_corpus(it, vectorizer)
hash_dtm <- get_dtm(corpus)

it <- itoken(movie_review$review[1:N], preprocess_function = tolower,
             tokenizer = word_tokenizer, chunks_number = 10)
v <- vocabulary(it, c(1L, 1L) )

vectorizer <- vocab_vectorizer(v)

it <- itoken(movie_review$review[1:N], preprocess_function = tolower,
             tokenizer = word_tokenizer, chunks_number = 10)

corpus <- create_corpus(it, vectorizer)
voacb_dtm <- get_dtm(corpus)
}
\seealso{
\link{create_corpus} \link{create_dtm} \link{create_tcm} \link{vocabulary}
}

